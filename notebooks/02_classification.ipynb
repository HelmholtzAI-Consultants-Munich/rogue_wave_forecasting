{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Rogue Wave Data with Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Imports\n",
    "\n",
    "Importing all required packages and define seed and number of cores to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.append('./')\n",
    "import utils\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "import shap\n",
    "from fgclustering import FgClustering\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(os.cpu_count()) # how many CPU cores are available on the current machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_jobs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = True\n",
    "num_cv = 10\n",
    "cases = [1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an ElasticNet Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the Model and Setting Hyperparameters\n",
    "\n",
    "- `C`: Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "- `l1_ratio`: The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'. Setting l1_ratio=0 is equivalent to using penalty='l2', while setting l1_ratio=1 is equivalent to using penalty='l1'. For 0 < l1_ratio <1, the penalty is a combination of L1 and L2.\n",
    "- `class_weight`: Weights associated with classes. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifer\n",
    "classifier = LogisticRegression(solver='saga', penalty = 'elasticnet', random_state=seed, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 20.0, 30., 4.0, 5.0, 10.0, 100.0], \n",
    "            'l1_ratio': [0, 0.2, 0.4, 0.5, 0.6, 0.8, 1],\n",
    "            'class_weight': ['balanced', None] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model\n",
    "\n",
    "For hyperparameter tuning, we use a k-fold crossvalidation with a stratified splitter that ensures we have enough data from each class in the training and validation set.\n",
    "\n",
    "For evaluation use confusion matrix, macro F1 score and balanced accuracy to account for potential class imbalances.\n",
    "\n",
    "We iterate over each binarization case:\n",
    "\n",
    "- case 1: class 0: target < 2.0 and class 1: target > 2.0 \n",
    "- case 2: class 0: target < 1.5 and class 1: target > 2.0\n",
    "- case 3: class 0: target < 1.5, class 1: 1.5 < target < 2.0 and class 2: target > 2.0\n",
    "\n",
    "The data that was preprocessed in `data_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for case 1\n",
      "The mean cross-validated score of the best model is 59.94% accuracy and the parameters of best prediction model are:\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'l1_ratio': 0}\n",
      "Balanced acc: 0.48613079320527613\n",
      "Macro F1 score: 0.2887679178671357\n",
      "Confusion matrix:\n",
      "[[ 77919 128195]\n",
      " [  1447   2119]]\n",
      "Building model for case 2\n",
      "The mean cross-validated score of the best model is 61.54% accuracy and the parameters of best prediction model are:\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'l1_ratio': 0}\n",
      "Balanced acc: 0.5490943238308509\n",
      "Macro F1 score: 0.37021833618012623\n",
      "Confusion matrix:\n",
      "[[41069 42659]\n",
      " [ 1399  2167]]\n",
      "Building model for case 3\n",
      "The mean cross-validated score of the best model is 44.6% accuracy and the parameters of best prediction model are:\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'l1_ratio': 0.4}\n",
      "Balanced acc: 0.3557478102475981\n",
      "Macro F1 score: 0.2747768302403449\n",
      "Confusion matrix:\n",
      "[[31859 22280 29588]\n",
      " [43902 35415 43070]\n",
      " [ 1078  1071  1417]]\n"
     ]
    }
   ],
   "source": [
    "for case in cases:\n",
    "\n",
    "    print(f'Building model for case {case}')\n",
    "\n",
    "    # Load and unpack the data\n",
    "    with open(f'../data/data_case{case}{\"_undersampled\" if undersample else \"\"}.pickle', 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = data\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_transformed = scaler.fit_transform(X_train)\n",
    "    X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "    # Tune hyperparameters\n",
    "    skf = StratifiedKFold(n_splits=num_cv).split(X_train_transformed, y_train)\n",
    "\n",
    "    gridsearch_classifier = GridSearchCV(classifier, hyperparameter_grid, cv=skf)\n",
    "    gridsearch_classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # Check the results\n",
    "    print(f'The mean cross-validated score of the best model is {round(gridsearch_classifier.best_score_*100, 2)}% accuracy and the parameters of best prediction model are:')\n",
    "    print(gridsearch_classifier.best_params_)\n",
    "\n",
    "    # Take the best estimator\n",
    "    model = gridsearch_classifier.best_estimator_\n",
    "    \n",
    "    # Predict labels\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "    print(f\"Balanced acc: {balanced_accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Macro F1 score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"Confusion matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "    # Save the model\n",
    "    data_and_model = [X_train_transformed, X_test_transformed, y_train, y_test, model]\n",
    "    \n",
    "    with open(f'../models/model_elnet_case{case}{\"_undersampled\" if undersample else \"\"}.pickle', 'wb') as handle:\n",
    "        pickle.dump(data_and_model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the Model and Setting Hyperparameters\n",
    "\n",
    "- `n_estimators`: The number of trees in the forest.\n",
    "- `max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "- `max_samples`: If bootstrap is True, the number of samples to draw from X to train each base estimator.\n",
    "- `criterion`: The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain.\n",
    "- `max_features`: The number of features to consider when looking for the best split.\n",
    "- `class weight`:\n",
    "  - The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n",
    "  - The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier. We set the oob_score = True, as OOB is a good approximation of the validation set score\n",
    "classifier = RandomForestClassifier(oob_score=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {'n_estimators': [1000], \n",
    "            'max_depth': [5, 10, 20, 30, 50], \n",
    "            'max_samples': [0.5, 0.8, 0.95],\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_features': ['sqrt','log2'],\n",
    "            'class_weight': ['balanced', 'balanced_subsample'] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model\n",
    "\n",
    "For hyperparameter tuning, we use a k-fold crossvalidation with a stratified splitter that ensures we have enough data from each class in the training and validation set.\n",
    "\n",
    "For evaluation use confusion matrix, macro F1 score and balanced accuracy to account for potential class imbalances.\n",
    "\n",
    "We iterate over each binarization case:\n",
    "\n",
    "- case 1: class 0: target < 2.0 and class 1: target > 2.0 \n",
    "- case 2: class 0: target < 1.5 and class 1: target > 2.0\n",
    "- case 3: class 0: target < 1.5, class 1: 1.5 < target < 2.0 and class 2: target > 2.0\n",
    "\n",
    "The data that was preprocessed in `data_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for case 1\n"
     ]
    }
   ],
   "source": [
    "for case in cases:\n",
    "\n",
    "    print(f'Building model for case {case}')\n",
    "\n",
    "    # Load and unpack the data\n",
    "    with open(f'../data/data_case{case}{\"_undersampled\" if undersample else \"\"}.pickle', 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = data\n",
    "\n",
    "    # Tune hyperparameters\n",
    "    skf = StratifiedKFold(n_splits=num_cv).split(X_train, y_train)\n",
    "    \n",
    "    gridsearch_classifier = GridSearchCV(classifier, hyperparameter_grid, cv=skf, verbose=0, n_jobs=n_jobs)\n",
    "    gridsearch_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Check the results\n",
    "    print(f'The mean cross-validated score of the best model is {round(gridsearch_classifier.best_score_*100, 2)}% accuracy and the parameters of best prediction model are:')\n",
    "    print(gridsearch_classifier.best_params_)\n",
    "\n",
    "    # Take the best estimator\n",
    "    model = gridsearch_classifier.best_estimator_\n",
    "    \n",
    "    # Predict labels\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"Balanced acc: {balanced_accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Macro F1 score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"Confusion matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "    # Save the model\n",
    "    data_and_model = [X_train, X_test, y_train, y_test, model]\n",
    "    \n",
    "    with open(f'../models/model_randomforest_case{case}{\"_undersampled\" if undersample else \"\"}.pickle', 'wb') as handle:\n",
    "        pickle.dump(data_and_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_model",
   "language": "python",
   "name": "kernel_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
