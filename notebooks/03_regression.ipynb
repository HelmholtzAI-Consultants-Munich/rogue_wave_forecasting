{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Rogue Wave Data with Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Imports\n",
    "\n",
    "Importing all required packages and define seed and number of cores to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.append('./')\n",
    "import utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.cpu_count()) # how many CPU cores are available on the current machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_jobs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = True\n",
    "num_cv = 10\n",
    "case = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an ElasticNet Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the Model and Setting Hyperparameters\n",
    "\n",
    "- `l1_ratio`: The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'. Setting l1_ratio=0 is equivalent to using penalty='l2', while setting l1_ratio=1 is equivalent to using penalty='l1'. For 0 < l1_ratio <1, the penalty is a combination of L1 and L2.\n",
    "- `selection`: If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifer\n",
    "classifier = ElasticNet(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = { \n",
    "    'l1_ratio': [0, 0.2, 0.4, 0.5, 0.6, 0.8, 1],\n",
    "    'selection': ['cyclic', 'random'] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model\n",
    "\n",
    "For hyperparameter tuning, we use a k-fold crossvalidation with a stratified splitter that ensures we have enough rogue wave data in the training and validation set.\n",
    "\n",
    "For evaluation use MSE, R^2 and PSearman correlation.\n",
    "\n",
    "We load the case 1 data that was preprocessed in `data_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Building model for case {case}')\n",
    "\n",
    "# Load and unpack the data\n",
    "with open(f'../data/data_reg_case{case}{\"_undersampled\" if undersample else \"\"}.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "data_train, data_test = data\n",
    "y_train = data_train['AI_10min']\n",
    "y_train_cat = data_train['AI_10min_cat']\n",
    "X_train = data_train.drop(columns=['AI_10min', 'AI_10min_cat'])\n",
    "y_test = data_test['AI_10min']\n",
    "X_test = data_test.drop(columns=['AI_10min', 'AI_10min_cat'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "# Tune hyperparameters\n",
    "skf = StratifiedKFold(n_splits=num_cv).split(X_train_transformed, y_train_cat)\n",
    "\n",
    "gridsearch_classifier = GridSearchCV(classifier, hyperparameter_grid, cv=skf)\n",
    "gridsearch_classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Check the results\n",
    "print(f'The mean cross-validated score of the best model is {round(gridsearch_classifier.best_score_, 3)} and the parameters of best prediction model are:')\n",
    "print(gridsearch_classifier.best_params_)\n",
    "\n",
    "# Take the best estimator\n",
    "model = gridsearch_classifier.best_estimator_\n",
    "\n",
    "# Predict labels\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "print(f\"Test set MSE: {round(mean_squared_error(y_test, y_pred), 3)}\")\n",
    "print(f\"Test set R^2: {round(r2_score(y_test, y_pred), 3)}\")\n",
    "print(f\"Test set Spearman R: {round(spearmanr(y_test, y_pred).correlation, 3)}\")\n",
    "\n",
    "utils.plot_predictions(y_true=y_test, y_pred=y_pred, save=f\"../results/regression_performance_elnet_case_{case}\")\n",
    "\n",
    "# Save the model\n",
    "data_and_model = [data_train, data_test, model]\n",
    "\n",
    "with open(f'../models/reg_model_elnet_case{case}{\"_undersampled\" if undersample else \"\"}.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_and_model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the Model and Setting Hyperparameters\n",
    "\n",
    "- `n_estimators`: The number of trees in the forest.\n",
    "- `max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "- `max_samples`: If bootstrap is True, the number of samples to draw from X to train each base estimator.\n",
    "- `criterion`: The function to measure the quality of a split. Supported criteria are “squared_error” for the mean squared error, which is equal to variance reduction as feature selection criterion and minimizes the L2 loss using the mean of each terminal node, “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits, “absolute_error” for the mean absolute error, which minimizes the L1 loss using the median of each terminal node, and “poisson” which uses reduction in Poisson deviance to find splits. Training using “absolute_error” is significantly slower than when using “squared_error”.\n",
    "- `max_features`: The number of features to consider when looking for the best split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier. We set the oob_score = True, as OOB is a good approximation of the validation set score\n",
    "classifier = RandomForestRegressor(oob_score=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {'n_estimators': [1000], \n",
    "            'max_depth': [5, 10, 20, 30], \n",
    "            'max_samples': [0.8],\n",
    "            'criterion': ['squared_error', 'poisson'],\n",
    "            'max_features': ['sqrt','log2'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model\n",
    "\n",
    "For hyperparameter tuning, we use a k-fold crossvalidation with a stratified splitter that ensures we have enough data from each class in the training and validation set.\n",
    "\n",
    "For evaluation use confusion matrix, macro F1 score and balanced accuracy to account for potential class imbalances.\n",
    "\n",
    "We iterate over each binarization case:\n",
    "\n",
    "- case 1: class 0: target < 2.0 and class 1: target > 2.0 \n",
    "- case 2: class 0: target < 1.5 and class 1: target > 2.0\n",
    "- case 3: class 0: target < 1.5, class 1: 1.5 < target < 2.0 and class 2: target > 2.0\n",
    "\n",
    "The data that was preprocessed in `data_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Building model for case {case}')\n",
    "\n",
    "# Load and unpack the data\n",
    "with open(f'../data/data_reg_case{case}{\"_undersampled\" if undersample else \"\"}.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "data_train, data_test = data\n",
    "y_train = data_train['AI_10min']\n",
    "y_train_cat = data_train['AI_10min_cat']\n",
    "X_train = data_train.drop(columns=['AI_10min', 'AI_10min_cat'])\n",
    "y_test = data_test['AI_10min']\n",
    "X_test = data_test.drop(columns=['AI_10min', 'AI_10min_cat'])\n",
    "\n",
    "# Tune hyperparameters\n",
    "skf = StratifiedKFold(n_splits=num_cv).split(X_train, y_train_cat)\n",
    "\n",
    "gridsearch_classifier = GridSearchCV(classifier, hyperparameter_grid, cv=skf)\n",
    "gridsearch_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Check the results\n",
    "print(f'The mean cross-validated score of the best model is {round(gridsearch_classifier.best_score_, 3)} and the parameters of best prediction model are:')\n",
    "print(gridsearch_classifier.best_params_)\n",
    "\n",
    "# Take the best estimator\n",
    "model = gridsearch_classifier.best_estimator_\n",
    "\n",
    "# Predict labels\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Test set MSE: {round(mean_squared_error(y_test, y_pred), 3)}\")\n",
    "print(f\"Test set R^2: {round(r2_score(y_test, y_pred), 3)}\")\n",
    "print(f\"Test set Spearman R: {round(spearmanr(y_test, y_pred).correlation, 3)}\")\n",
    "\n",
    "utils.plot_predictions(y_true=y_test, y_pred=y_pred, save=f\"../results/regression_performance_elnet_case_{case}\")\n",
    "\n",
    "# Save the model\n",
    "data_and_model = [data_train, data_test, model]\n",
    "\n",
    "with open(f'../models/reg_model_randomforest_case{case}{\"_undersampled\" if undersample else \"\"}.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_and_model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rogue_wave",
   "language": "python",
   "name": "rogue_wave"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
