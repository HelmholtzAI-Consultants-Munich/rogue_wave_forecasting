{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Rogue Wave Data with Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('./')\n",
    "import utils\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from fgclustering import FgClustering\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.cpu_count()) # ask the question how many CPU cores are available on the current machine\n",
    "n_jobs = 10\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Rogue Wave Data\n",
    "\n",
    "Loading the data that was preprocessed in `data_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 1 \n",
    "\n",
    "# Load and unpack the data\n",
    "with open(f'./data_case{case}.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "X_train = data[0]\n",
    "X_test = data[1]\n",
    "y_train_cat = data[2]\n",
    "y_test_cat = data[3]\n",
    "\n",
    "y_train = X_train.AI_10min\n",
    "y_test = X_test.AI_10min\n",
    "\n",
    "X_train = X_train.drop(columns=['AI_10min'])\n",
    "X_test = X_test.drop(columns=['AI_10min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Random Forest Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_grid_classifier = {'n_estimators': [250, 750], \n",
    "            'max_depth': [5, 10, 20], \n",
    "            'max_samples': [0.8],\n",
    "            'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "            'max_features': ['sqrt','log2'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classifier. We set the oob_score = True, as OOB is a good approximation of the validation set score\n",
    "classifier = RandomForestRegressor(oob_score=True, random_state=seed, n_jobs=n_jobs)\n",
    "\n",
    "num_cv = 5\n",
    "skf_gen = StratifiedKFold(num_cv).split(X_train, y_train_cat)\n",
    "\n",
    "gridsearch_classifier = GridSearchCV(classifier, hyper_grid_classifier, cv=skf_gen)\n",
    "gridsearch_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results\n",
    "print(f'The mean cross-validated score of the best model is {round(gridsearch_classifier.best_score_*100, 2)}% accuracy and the parameters of best prediction model are:')\n",
    "print(gridsearch_classifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the best estimator\n",
    "model = gridsearch_classifier.best_estimator_\n",
    "\n",
    "# predict label \n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {round(mean_squared_error(y_test, y_pred), 3)}\")\n",
    "print(f\"R^2: {round(r2_score(y_test, y_pred), 3)}\")\n",
    "print(f\"Spearman R: {round(spearmanr(y_test, y_pred).correlation, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='b')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Line y = x for reference\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with joblib\n",
    "data_and_model = [X_train, X_test, y_train, y_test, y_train_cat, y_test_cat, model]\n",
    "\n",
    "with open(f'./model_randomforest_regression.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_and_model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and unpack the data\n",
    "with open(f'./model_randomforest_regression.pickle', 'rb') as handle:\n",
    "    data_and_model = pickle.load(handle)\n",
    "\n",
    "X_train = data_and_model[0]\n",
    "X_test = data_and_model[1]\n",
    "y_train = data_and_model[2]\n",
    "y_test = data_and_model[3]\n",
    "y_train = data_and_model[4]\n",
    "y_test = data_and_model[5]\n",
    "model = data_and_model[6]\n",
    "\n",
    "# is the model performing reasonably on the training data?\n",
    "print(f'Model Performance on training data: {round(r2_score(y_train, model.predict(X_train))*100,2)} R^2.')\n",
    "\n",
    "# is the model performing reasonably on the test data?\n",
    "print(f'Model Performance on test data: {round(r2_score(y_test, model.predict(X_test))*100,2)} R^2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability for Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Feature Importance\n",
    "\n",
    "An alternative to Permutation Feature Importance is the Random Forest specific feature importance method based on the mean decrease in impurity. The mean decrease in impurity is defined as the total decrease in node impurity averaged over all trees of the ensemble. This Feature Importances is directly provided by the fitted attribute feature_importances_ .\n",
    "\n",
    "Lets plot the feature importance based on mean decrease in impurity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_impurity_feature_importance(model .feature_importances_, names=X_train.columns, title=\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation with Forest-Guided Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fgc = X_train.copy()\n",
    "data_fgc[\"target\"] = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run FGC with subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iterations = 25   # Number of times dataset will be subsampled\n",
    "sample_size = 1000           # Number of samples in the subsampled dataset\n",
    "max_K = 10                   # Maximum K for the FGC\n",
    "\n",
    "k_result =  dict((i,0) for i in range(1, max_K)) # Dictionary to store the result\n",
    "\n",
    "for i in range(number_of_iterations):\n",
    "    # sample the dataset\n",
    "    data_sample = data_fgc.sample(\n",
    "        n = sample_size, replace = False, random_state = i\n",
    "        ) # setting random state for reproducibility\n",
    "    # instantiate the fgc object on the subsampled dataset and run it:\n",
    "    fgc = FgClustering(\n",
    "        model=rf, data=data_sample, target_column='target'\n",
    "        )\n",
    "    fgc.run(\n",
    "        method_clustering = 'pam', max_K = max_K, \n",
    "        discart_value_JI = 0.60, bootstraps_JI = 100, n_jobs = n_jobs, verbose = 0\n",
    "        )\n",
    "    # save the result\n",
    "    k_result[fgc.k] += 1\n",
    "\n",
    "pd.DataFrame(k_result.items(), columns=['k','count']).sort_values(by='count', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# create the fgc object\n",
    "fgc = FgClustering(model=model, data=data_fgc, target_column=\"target\")\n",
    "\n",
    "fgc.run(\n",
    "    number_of_clusters = k, method_clustering = 'pam', \n",
    "    bootstraps_JI = 100, bootstraps_p_value = 100, discart_value_JI = 0.6\n",
    "    ,n_jobs = n_jobs, verbose = 2 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fgc[\"target_predicted\"] = model.predict(X_train)\n",
    "fgc.calculate_statistics(data=data_fgc, target_column='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgc.plot_feature_importance()\n",
    "fgc.plot_decision_paths()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
